{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"},"colab":{"provenance":[],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"-mh679lW5v_t"},"source":["#**Module 3: Data Wrangling Part 1**\n","In this module, you will learn how to\n","* Create dataframes with data subsets\n","* Reduce the number of columns and rows in a dataset\n","* Explain why reducing data is so important\n","\n","**Be sure to expand all the hidden cells, run all the code, and do all the exercises--you will need the techniques for the lesson lab!**"]},{"cell_type":"markdown","source":["##**The Goal**\n","Big datasets are, well, big. We aren't talking about thousands of rows and 10 or so attributes (aka features, dimensions, or variables); we are talking about billions of rows with many thousands of dimensions. Think all-purchases-on-Amazon.com-the-Saturday-before-Christmas big.\n","\n","If you try to process that much data on your computer, guess what happens?\n","\n","<img src=\"https://t4.ftcdn.net/jpg/05/59/39/65/360_F_559396565_1OMlX6HmsVNNuTLIBKXFQibqycB2vXQg.jpg\">\n","\n","I will neither confirm nor deny that I may be speaking from experience. Ahem.\n","\n","So, in terms of big datasets, **BIGGER** does **NOT** mean **BETTER**. Instead, you'll want to think critically about what data from the big pool you need for your analysis and then work with only that subset.\n"],"metadata":{"id":"4Eygh8373bYQ"}},{"cell_type":"markdown","metadata":{"id":"bnVNWu8SBjIg"},"source":["#**0. Preparation and Setup**\n","We are working with our adult dataset again, so we're loading our libraries and our dataset just like last time, only with the url variable, which simplifies any dataset import for later."]},{"cell_type":"code","metadata":{"id":"vui8bv375v_v"},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","#Reading in the data as adult dataframe\n","adult = pd.read_csv(\"https://raw.githubusercontent.com/shstreuber/Data-Mining/master/data/adult.data.simplified25.csv\")\n","\n","#Verifying that we can see the data\n","adult.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#**1. Subsetting and Aggregating Data**\n"],"metadata":{"id":"NpW0VkiDE-Ua"}},{"cell_type":"markdown","source":["So, the idea is to reduce the dataset with which you are working to the smallest possible size and include ONLY the attributes AND the rows\n","that are useful and meaningful. This requires editing your dataset:\n","\n","1. When you reduce the number of attributes or the number of rows, this is called **SUBSETTING**\n","3. When you summarize rows based on a common attribute (like, \"all married people\" or \"all people under 17\"), that is called **AGGREGATION**\n","\n","Both together are called **DIMENSIONALITY REDUCTION**\n","\n","The goal is to think critically (and do some math) about what the best attributes and rows are to include BEFORE you start processing your data. In other words: **PRE-PROCESSING**.\n","\n","Let's get started!"],"metadata":{"id":"jK2X-XTJHdSi"}},{"cell_type":"markdown","metadata":{"id":"x9M7rrse4REN"},"source":["##**1.1 Slicing and Subsetting**\n","Slicing and subsetting are related. While Slicing requires indexing (i.e. using the absolute row and column numbers, starting with 0), subsetting does not require indexing.\n","\n","##**Slicing Magic: The iloc Operator**\n","\n","**iloc** allows you to define exactly the \"fields\" that you want to see:\n","\n","* `df.iloc[0:5,]` shows you the ROWS with the indices 0 through 4 (the first 5)\n","* `df.iloc[:,0:5]` shows you the first five COLUMNS\n","* `df.iloc[0:5,0:5]` shows you the first five ROWS and the first five COLUMNS\n","\n","Practice this below (remember to click on the \"start\" button to execute the code):"]},{"cell_type":"code","metadata":{"id":"SPAPYtss4REN"},"source":["# Looking at only the first 5 rows\n","adult.iloc[0:5,]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7PXaYuJo4REO"},"source":["Now, use the field below to display only the first five columns"]},{"cell_type":"code","metadata":{"id":"61iGrpid4REO"},"source":["adult.iloc[:,0:5]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h2cYCamd4REP"},"source":["And now the first five columns and the first five rows:"]},{"cell_type":"code","metadata":{"id":"oqhjCqiL4REP"},"source":["adult.iloc[0:5,0:5]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"puW0qj1z4REP"},"source":["##Your Turn##\n","Now use the code field below to save the first five columns and the first five rows into their own dataframe like this:\n","\n","`adult_[yourname]_short = adult.iloc[` ... followed by the actual iloc code and then display the contents:"]},{"cell_type":"code","metadata":{"id":"ufy8R7mf4REQ"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6koY5UpO4REQ"},"source":["##**1.2 Subsetting**\n","Subsetting does not require knowing the index numbers for rows or columns. Instead, it sets up row-based filters. For more about subsetting, click [here](https://cmdlinetips.com/2018/02/how-to-subset-pandas-dataframe-based-on-values-of-a-column/) or continue below.\n","\n","What if we want to see only the people who are 90 years old?"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"EMHBdAyk4REQ"},"source":["adult[adult['age'] == 90] # NOTE here that == means \"equal to\"; it is NOT the mathematical equality operator!"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qNkLgXKJ4RER"},"source":["Now use <= 20 to find all the people who are younger than or equal to 20:"]},{"cell_type":"code","metadata":{"id":"PwAh14s24RER"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JLTiTEiH4RER"},"source":["How about all the people who are older than 75?"]},{"cell_type":"code","metadata":{"id":"2iqOnOzx4RES"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TvO0ixcW4RES"},"source":["If you are subsetting with strings, the strings need to be in single or double quotes. Below, we are looking for everyone with a Bachelors degree:"]},{"cell_type":"code","metadata":{"id":"cRHGhqXb4RES"},"source":["adult[adult['education'] == 'Bachelors']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Your Turn\n","Find all the people in the United-States. Then, find all the people from Cuba!"],"metadata":{"id":"w-TvEXPqMVp6"}},{"cell_type":"code","source":[],"metadata":{"id":"3i-oz48nMj0Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"jVgRw5SBMyCi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LIevWhua4RET"},"source":["##**1.3 Building your own reduced dataset**\n","Now you have all the tools you need to reduce your dataset (without changing its values--we'll do that in our next step) to a size that's\n","\n","1. Manageable for your hardware\n","2. Practical for you to work with\n","\n","One of the WORST things you can do to yourself, your computer, and your instructor is to keep working with the HUGE dataset. That often leads to confusion and doesn't work well. Use **discernment and critical thinking** when working with data. Your future employer will thank you!\n","\n","Below are some of the techniquest that will help you:"]},{"cell_type":"code","metadata":{"id":"pUhbaLBA4RET"},"source":["# Selecting multiple columns at the same time extracts a new DataFrame from your existing DataFrame.\n","# For selection of multiple columns, the syntax is: square-brace selection with a list of column names,\n","# e.g. data[['column_name_1', 'column_name_2']]\n","adult[['age','education','sex']]"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["reduced_data = adult[['age','education','sex']]"],"metadata":{"id":"m4N2NC5FakKy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["reduced_data"],"metadata":{"id":"yf-HoDy9apL4"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n6-nmSVd4REV"},"source":["# Alternately, you can use numeric indexing with the iloc selector and a list of column numbers, e.g. data.iloc[:, [0,1,20,22]]\n","# This allows you to specify colums, as well\n","adult.iloc[0:5,[0,1,7,10,11]]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5e1ME-vf4REV"},"source":["**AAAAAAND**, as they say, the piece de resistance: Combining row filters and column filters!"]},{"cell_type":"code","metadata":{"id":"nqDtLKCt4REV"},"source":["adult[adult['education'] == 'Bachelors'].iloc[0:5,[0,1,2,10,11]]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q15gLnAQ4REW"},"source":["##Your Turn\n","Now, complete the code below to build an adult_small dataframe with rows 70-80 and all columns. You will need this dataframe later. (REMEMBER that the index numbers start with 0!!!!!!)"]},{"cell_type":"code","metadata":{"id":"qydDvlni4REW"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Sqw4bREq4REW"},"source":["## **1.4. Aggregation and Dimensionality Reduction**\n","So far, we have learned the mechanics of making our datasets smaller based on practical deliberations--specifically, what columns and what rows we want in order to produce a valid analysis. The goal of Dimensionality Reduction is similar: To make our dataset smaller, so it's easier to handle. However, the reasons are different.\n","\n","With Dimensionality Reduction, we are looking at **the data themselves** to show us ways in which they can be summarized and simplified. This can happen as follows:\n","- Column-based: Eliminate attributes that are bascially duplicates of one another\n","- Row-based: Aggregate similar attribute levels in one level\n","- Binning and Bucketing\n","- Normalization of values\n","\n","We will learn about the first two bullet points below; we will come back to the last two bullet points once we have stepped through data transformation."]},{"cell_type":"markdown","metadata":{"id":"D24Vyfhi4REW"},"source":["###Column-Based Dimensionality Reduction###\n","In the adult dataset, 'maritalstatus' and 'relationship' look very closely related. If there is a 1:1 relationship between all data values (or at least most of them), this means that the information is really duplicate, so we can choose to eliminate one of these columns.\n","\n","Let's see if we need both of them."]},{"cell_type":"code","metadata":{"id":"cHLv8yaJ4REX"},"source":["household=adult[['relationship', 'maritalstatus']]\n","household.groupby('relationship').sum()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s3b1Y6qf4REX"},"source":["The output shows us that we have many different values in 'maritalstatus' that are tied to one value in 'relationship.' In relational database terms (for those of you who have taken a database class), this is basically a many-to-one relationship. What we are looking for is a one-to-one relationship. So, 'maritalstatus' and 'relationship' won't work.\n","\n","What if we look at this relationship the other way around, using 'maritalstatus' on the left, though?"]},{"cell_type":"code","metadata":{"id":"SgRe5-8U4REX"},"source":["household.groupby('maritalstatus').sum()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_Yq-tEZe4REY"},"source":["Let's try setting a matrix that shows all unique combinations of 'relationship' and 'maritalstatus'. We will use relationship as index and use apply and lambda to sort maritalstatus according to that index."]},{"cell_type":"code","metadata":{"id":"0YarfhmT4REY"},"source":["household2 = household.groupby('relationship').apply(lambda x: x['maritalstatus'].unique())\n","household2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"95LR1LoW4REY"},"source":["Can you turn this around and use 'maritalstatus' as index? Use the field below."]},{"cell_type":"code","metadata":{"id":"GYr6Ogoq4REZ"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GSEdr6Tx4REZ"},"source":["So, we've looked at the connection between 'relationship' and 'maritalstatus' from all different sides--and we are still finding these one-to-many relationships that go both ways. Unless we join each unique value from one attribute with each unique value in the other attribute into the same column, we will need to keep both columns.\n","\n","Let's see if there is a better connection between 'educationyears' and 'education.'"]},{"cell_type":"code","metadata":{"id":"iqI4IWpl4REZ"},"source":["degree=adult[['educationyears', 'education']]\n","# degree.sort_values('educationyears')  # This gives us the entire list sorted, but we want to display the unique values\n","# degree.groupby('educationyears').sum() # That's what we had before--we can do better!\n","\n","# Let's try setting a matrix that is indexed by educationyears. This is what apply and lambda x do.\n","degree2 = degree.groupby('educationyears').apply(lambda x: x['education'].unique())\n","degree2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5Ndk8oWX4REa"},"source":["##Your Turn\n","\n","Can you turn this around and use 'education' as index?"]},{"cell_type":"code","metadata":{"id":"Tgs_O_1A4REa"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j9vcCqgq4REa"},"source":["In contrast to 'maritalstatus' and 'relationship, it seems that 'educationyears' and 'education' are uniquely related. This means we need only one of these columns. Since working with numbers is always easier, we choose 'educationyears' and will eliminate 'education'.\n","To drop a columns, we can use a couple of methods:\n","1. We can rebuild the dataframe (or a different dataframe) with only the columns that we want, for example: `adult4=adult[['age','race','sex','educationyears','income']]`--that kind of thing\n","2. We can use the pandas drop function as explained here: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html. Another explanation with a data frame sample is here: http://cmdlinetips.com/2018/04/how-to-drop-one-or-more-columns-in-pandas-dataframe/.  This is a better way to modify your dataframe.\n","\n","Now, let's build an adult4 dataframe that contains all columns of the adult dataframe EXCEPT 'education'"]},{"cell_type":"code","metadata":{"id":"olMdX4qI4REb"},"source":["adult4 = adult.drop(['education'], axis = 1)\n","adult4"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NzlZ2M-94REb"},"source":["### Row-Based Dimensionality Reduction\n","Along with setting a filter and storing the output in a separate dataframe as we have seen at the beginning of this file, you can also remove rows from a dataframe by using the “drop” function. To do so, you will need to  specify axis=0.\n","\n","Drop() removes rows based on “labels”, rather than numeric indexing. To delete rows based on their numeric position / index, use iloc to reassign the dataframe values, as in the examples below.\n","\n","Read more about drop() and axis values (0 or 1) [here](https://www.shanelynn.ie/pandas-drop-delete-dataframe-rows-columns/)."]},{"cell_type":"code","metadata":{"id":"V9zWzlPz4REb"},"source":["#Delete the rows with label 'white'\n","#For label-based deletion, set the index first on the dataframe:\n","adult5 = adult\n","adult5 = adult5.set_index('race')\n","adult5.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WLRvSGdg4REc"},"source":["# Now we delete the rows where the index shows \"White\"\n","adult5 = adult5.drop('White', axis=0) # Delete all rows with label 'White'\n","adult5.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4ocn9W4Y4REc"},"source":["# We can also delete the rows with labels 0,1,5\n","adult5 = adult.drop([0,1,5], axis=0)\n","adult5.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m5pvewX-4REc"},"source":["Check out the results above--notice how indices 0,1, and 5 are missing?\n","\n","##Your Turn\n","\n","Now, put everything together that you have learned so far, experiment a bit, and then use the space below to build a new adult6 dataframe that contains only rows of male individuals."]},{"cell_type":"code","metadata":{"id":"tZpnf_124REc"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KltxTCDYCr6S"},"outputs":[],"source":[]}]}